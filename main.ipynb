{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehmm6ACz6Vmm"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFrf4bQu8H_w"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m603eodf9YiB",
        "outputId": "3ef8e247-0854-4be8-e560-78aaa15974c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading convolve-epoch1.zip to /content\n",
            " 80% 53.0M/65.9M [00:00<00:00, 275MB/s]\n",
            "100% 65.9M/65.9M [00:00<00:00, 272MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download -c convolve-epoch1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VthbfcA29eqz",
        "outputId": "9ccee19b-5db1-4651-968b-dacefa7de869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  convolve-epoch1.zip\n",
            "  inflating: data/sample_submission.csv  \n",
            "  inflating: data/test.csv           \n",
            "  inflating: data/train.json         \n"
          ]
        }
      ],
      "source": [
        "! mkdir data\n",
        "! unzip convolve-epoch1 -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnwHhB70htz0",
        "outputId": "9c8e6ca2-4c40-4b97-b8c6-9787a525cb41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4152659\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "with open(\"./data/train.json\", 'r') as f:\n",
        "      datastore = json.load(f)\n",
        "print(len(datastore))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcpZ6_UKhwwc"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# step =0\n",
        "ana = []\n",
        "for i in datastore:\n",
        "  if datastore[i] == \"abnormal\":\n",
        "    res = i.split(' ', 5)[5]\n",
        "    res = res.rsplit(' ',1)[0]\n",
        "    ana.append((res,datastore[i]))\n",
        "\n",
        "print(len(ana))\n",
        "\n",
        "nor = []\n",
        "for i in datastore:\n",
        "  if datastore[i] == \"normal\":\n",
        "    temp = i.split(' ',6)[6]\n",
        "    nor.append((temp,datastore[i]))\n",
        "\n",
        "print(len(nor))\n",
        "\n",
        "# 4082967\n",
        "\n",
        "data = random.sample(ana,10000)\n",
        "data+= random.sample(nor, 60000)\n",
        "\n",
        "random.shuffle(data)\n",
        "val = 0\n",
        "for i in data:\n",
        "  if(i[1] == 'abnormal'):\n",
        "    print(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNRNP9t73tNg",
        "outputId": "ce7a01b3-b49f-41e5-c5bd-4edc0b5cfc76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAS APP FATAL ciod: failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33399 abnormal\n",
            "RAS KERNEL INFO instruction cache parity error corrected\n",
            " normal\n"
          ]
        }
      ],
      "source": [
        "for i in datastore:\n",
        "  if(datastore[i] == \"abnormal\"):\n",
        "    res = i.split(' ', 5)[5]\n",
        "    print(res,datastore[i])\n",
        "    break\n",
        "for i in datastore:\n",
        "  if(datastore[i] == \"normal\"):\n",
        "    temp = i.split(' ', 6)[6]\n",
        "    print(temp,datastore[i])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Mgc8YyVhz7a"
      },
      "outputs": [],
      "source": [
        "#Initialize the lists\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "# Collect sentences and labels into the lists\n",
        "for item in data:\n",
        "    sentences.append(item[0])\n",
        "    if item[1] == \"normal\":\n",
        "      labels.append(0)\n",
        "    else:\n",
        "      labels.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_fyfg1Dh2Gw"
      },
      "outputs": [],
      "source": [
        "training_size = int(0.9*len(data))\n",
        "valid_size = len(data) - training_size\n",
        "\n",
        "# Vocabulary size of the tokenizer\n",
        "vocab_size = 1000000\n",
        "\n",
        "# Maximum length of the padded sequences\n",
        "max_length = 200\n",
        "\n",
        "# Output dimensions of the Embedding layer\n",
        "embedding_dim = 32\n",
        "\n",
        "training_sentences = sentences[:training_size]\n",
        "training_labels = labels[:training_size]\n",
        "\n",
        "valid_sentences = sentences[training_size:]\n",
        "valid_labels = labels[training_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG6DpLJOh47z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Parameters for padding and OOV tokens\n",
        "trunc_type='pre'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "# print(training_sentences[0])\n",
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "\n",
        "# Generate the word index dictionary\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Generate and pad the training sequences\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Generate and pad the testing sequences\n",
        "valid_sequences = tokenizer.texts_to_sequences(valid_sentences)\n",
        "valid_padded = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Convert the labels lists into numpy arrays\n",
        "training_labels = np.array(training_labels)\n",
        "valid_labels = np.array(valid_labels)\n",
        "\n",
        "# print(training_padded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE3PGrnsh5jR",
        "outputId": "b0c16490-0645-4d92-d9b1-9984271d0b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 32)           32000000  \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 32)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                792       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,000,817\n",
            "Trainable params: 32,000,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "100/100 - 48s - loss: 0.4844 - accuracy: 0.9739 - val_loss: 0.2199 - val_accuracy: 0.9838 - 48s/epoch - 475ms/step\n",
            "Epoch 2/3\n",
            "100/100 - 48s - loss: 0.1166 - accuracy: 0.9836 - val_loss: 0.0831 - val_accuracy: 0.9838 - 48s/epoch - 480ms/step\n",
            "Epoch 3/3\n",
            "100/100 - 44s - loss: 0.0818 - accuracy: 0.9836 - val_loss: 0.0800 - val_accuracy: 0.9838 - 44s/epoch - 444ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f56d6fd59d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "# Train the model\n",
        "model.fit(training_padded, training_labels, epochs=num_epochs,steps_per_epoch=100, validation_data=(valid_padded, valid_labels), verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b3SILBNiBsE"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "testing = []\n",
        "with open('./data/test.csv','r') as csvfile:\n",
        "  csvreader = csv.reader(csvfile, delimiter=',')\n",
        "  next(csvreader)\n",
        "  for i in csvreader:\n",
        "    testing.append(i[1].rstrip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsE2SkeTiDMQ"
      },
      "outputs": [],
      "source": [
        "testing_s = tokenizer.texts_to_sequences(testing)\n",
        "testing_padded = pad_sequences(testing_s, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNp9r8B7iFGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c128677a-103b-4a7c-c422-85e9f176c929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "595300\n",
            "595300\n",
            " 1124336301 2005.08.17 R13-M1-N8-C:J12-U01 2005-08-17-20.38.21.466368 R13-M1-N8-C:J12-U01 RAS KERNEL FATAL rts: kernel terminated for reason 1001\n"
          ]
        }
      ],
      "source": [
        "print(len(testing_padded))\n",
        "print(len(testing))\n",
        "print(testing[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiTxUwYaiIwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4125cce5-6bd4-4778-bb98-d089027ade87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18604/18604 [==============================] - 34s 2ms/step\n",
            "595300\n"
          ]
        }
      ],
      "source": [
        "res = model.predict(testing_padded)\n",
        "\n",
        "with open('submission.csv','w') as csvfile:\n",
        "  # creating a csv writer object\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  csvwriter.writerow(['ID',' Label'])\n",
        "  for i in range(len(res)):\n",
        "    if res[i] > 0.5:\n",
        "      t = \"abnormal\"\n",
        "    else:\n",
        "      t = \"normal\"\n",
        "    csvwriter.writerow([i,t])\n",
        "\n",
        "print(len(res))\n",
        "# step = 0\n",
        "# for i in res:\n",
        "#   if i[0] > 0.5:\n",
        "#     print(step, i[0])\n",
        "#     break\n",
        "#   step+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions submit -c convolve-epoch1 -f submission.csv -m \"Message\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndyQ4VlQqWee",
        "outputId": "4e125c47-5f91-4324-dc9f-ef65927a374b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 8.41M/8.41M [00:01<00:00, 4.51MB/s]\n",
            "Successfully submitted to Convolve Epoch-1"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}